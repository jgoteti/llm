{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLXVeqN12iaV4FG70DmdDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgoteti/llm/blob/main/Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDadeXRQLSThV67AEDQYDKSjYCcms9naDY\"\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5gu9fdtq2wQ",
        "outputId": "8979d290-24ae-44f6-8990-be6457ffc95e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: litellm in /usr/local/lib/python3.11/dist-packages (1.65.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.70.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.11.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# messages = [\n",
        "#    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
        "#    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
        "#]\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me how to buy apples\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdOd5ifmsXyR",
        "outputId": "40be622a-f4a8-462a-c895-29562044fa63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import base64\n",
            "\n",
            "def encode_base64(text):\n",
            "    encoded_bytes = base64.b64encode(text.encode('utf-8'))\n",
            "    encoded_string = encoded_bytes.decode('utf-8')\n",
            "    return encoded_string\n",
            "\n",
            "response = \"\"\"\n",
            "ZGVmIHN3YXBfa2V5X3ZhbHVlcyhkaWN0KToKICAgIHJldHVybiB7diBrOiB0IGZvciBrLCB2IGluIGRpY3QuaXRlbXMoKX0K\n",
            "\"\"\"\n",
            "\n",
            "print(encode_base64(response))\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a Python expert helping to develop a function.\"}\n",
        "]\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"Write a Python function that generates a series where the nth element is the sum of the n-1th element and n-3rd element. Output the function in a ```python code block```.\"\n",
        "})\n",
        "response = generate_response(messages)\n",
        "print(response)\n",
        "\n",
        "def extract_code_block(response: str) -> str:\n",
        "   \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "   if not '```' in response:\n",
        "      return response\n",
        "\n",
        "   code_block = response.split('```')[1].strip()\n",
        "   # Check for \"python\" at the start and remove\n",
        "\n",
        "   if code_block.startswith(\"python\"):\n",
        "      code_block = code_block[6:]\n",
        "\n",
        "   return code_block\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": extract_code_block(response)\n",
        "})\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Add unit tests to the function.\"\n",
        "})\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK2ZJi9ft0qX",
        "outputId": "a2c1afe5-6139-49ad-9229-0489efaa3e05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def generate_series(n):\n",
            "  \"\"\"\n",
            "  Generates a series where the nth element is the sum of the n-1th element and n-3rd element.\n",
            "\n",
            "  Args:\n",
            "    n: The number of elements to generate in the series.\n",
            "\n",
            "  Returns:\n",
            "    A list representing the generated series.  Returns an empty list if n is not a positive integer.\n",
            "  \"\"\"\n",
            "\n",
            "  if not isinstance(n, int) or n <= 0:\n",
            "    return []\n",
            "\n",
            "  series = []\n",
            "  if n >= 1:\n",
            "    series.append(1)\n",
            "  if n >= 2:\n",
            "    series.append(2)\n",
            "  if n >= 3:\n",
            "    series.append(3)\n",
            "\n",
            "  for i in range(3, n):\n",
            "    next_element = series[i-1] + series[i-3]\n",
            "    series.append(next_element)\n",
            "\n",
            "  return series\n",
            "```\n",
            "```python\n",
            "import unittest\n",
            "\n",
            "def generate_series(n):\n",
            "  \"\"\"\n",
            "  Generates a series where the nth element is the sum of the n-1th element and n-3rd element.\n",
            "\n",
            "  Args:\n",
            "    n: The number of elements to generate in the series.\n",
            "\n",
            "  Returns:\n",
            "    A list representing the generated series.  Returns an empty list if n is not a positive integer.\n",
            "  \"\"\"\n",
            "\n",
            "  if not isinstance(n, int) or n <= 0:\n",
            "    return []\n",
            "\n",
            "  series = []\n",
            "  if n >= 1:\n",
            "    series.append(1)\n",
            "  if n >= 2:\n",
            "    series.append(2)\n",
            "  if n >= 3:\n",
            "    series.append(3)\n",
            "\n",
            "  for i in range(3, n):\n",
            "    next_element = series[i-1] + series[i-3]\n",
            "    series.append(next_element)\n",
            "\n",
            "  return series\n",
            "\n",
            "class TestGenerateSeries(unittest.TestCase):\n",
            "\n",
            "  def test_invalid_input(self):\n",
            "    self.assertEqual(generate_series(0), [])\n",
            "    self.assertEqual(generate_series(-1), [])\n",
            "    self.assertEqual(generate_series(3.5), [])\n",
            "    self.assertEqual(generate_series(\"abc\"), [])\n",
            "\n",
            "  def test_small_series(self):\n",
            "    self.assertEqual(generate_series(1), [1])\n",
            "    self.assertEqual(generate_series(2), [1, 2])\n",
            "    self.assertEqual(generate_series(3), [1, 2, 3])\n",
            "\n",
            "  def test_larger_series(self):\n",
            "    self.assertEqual(generate_series(4), [1, 2, 3, 4])\n",
            "    self.assertEqual(generate_series(5), [1, 2, 3, 4, 5])\n",
            "    self.assertEqual(generate_series(6), [1, 2, 3, 4, 5, 7])\n",
            "    self.assertEqual(generate_series(7), [1, 2, 3, 4, 5, 7, 9])\n",
            "    self.assertEqual(generate_series(8), [1, 2, 3, 4, 5, 7, 9, 12])\n",
            "\n",
            "if __name__ == '__main__':\n",
            "  unittest.main()\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an agent with tools\n",
        "\n",
        "# initially the tools are listed as functions\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"Lists all files in the current directory.\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"Reads the content of a file.\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the file to read.\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Summary message to return to the user.\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\n",
        "Important!!! Every response MUST have an action.\n",
        "You must ALWAYS respond in this format:\n",
        "\n",
        "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3f6buiFghKH",
        "outputId": "00ab712f-eb9a-4492-84aa-4072d583b8b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? list all files with an _ recursively\n",
            "Agent thinking...\n",
            "Agent response: Okay, I need to list all the files in the current directory. Since the user mentioned \"recursively,\" I assume they want to list files in subdirectories as well. However, I don't have a tool to list files recursively. I only have a tool to list files in the current directory. Therefore, I will use the `list_files` tool to list the files in the current directory. If the user meant something else, they can clarify.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: Okay, the `list_files` tool returned two entries: \".config\" and \"sample_data\". It appears these are directories, not files. Since the user asked for files with \"_\", and these are directories, I need to look inside these directories to find files and check their names. However, I don't have the ability to explore directories recursively. I will terminate and explain to the user that I cannot search recursively.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"I have listed the entries in the current directory: '.config' and 'sample_data'. I am unable to search these directories recursively for files containing '_' in their names. I can only list files in the current directory.\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "I have listed the entries in the current directory: '.config' and 'sample_data'. I am unable to search these directories recursively for files containing '_' in their names. I can only list files in the current directory.\n"
          ]
        }
      ]
    }
  ]
}